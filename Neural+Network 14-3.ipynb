{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 148.   85.  183.   89.  137.  116.   78.  115.  197.  125.  110.  168.\n",
      "  139.  189.  166.  100.  118.  107.  103.  115.  126.   99.  196.  119.\n",
      "  143.  125.  147.   97.  145.  117.  109.  158.   88.   92.  122.  103.\n",
      "  138.  102.   90.  111.  180.  133.  106.  171.  159.  180.  146.   71.\n",
      "  103.  105.  103.  101.   88.  176.  150.   73.  187.  100.  146.  105.\n",
      "   84.  133.   44.  141.  114.   99.  109.  109.   95.  146.  100.  139.\n",
      "  126.  129.   79.    0.   62.   95.  131.  112.  113.   74.   83.  101.\n",
      "  137.  110.  106.  100.  136.  107.   80.  123.   81.  134.  142.  144.\n",
      "   92.   71.   93.  122.  163.  151.  125.   81.   85.  126.   96.  144.\n",
      "   83.   95.  171.  155.   89.   76.  160.  146.  124.   78.   97.   99.\n",
      "  162.  111.  107.  132.  113.   88.  120.  118.  117.  105.  173.  122.\n",
      "  170.   84.   96.  125.  100.   93.  129.  105.  128.  106.  108.  108.\n",
      "  154.  102.   57.  106.  147.   90.  136.  114.  156.  153.  188.  152.\n",
      "   99.  109.   88.  163.  151.  102.  114.  100.  131.  104.  148.  120.\n",
      "  110.  111.  102.  134.   87.   79.   75.  179.   85.  129.  143.  130.\n",
      "   87.  119.    0.   73.  141.  194.  181.  128.  109.  139.  111.  123.\n",
      "  159.  135.   85.  158.  105.  107.  109.  148.  113.  138.  108.   99.\n",
      "  103.  111.  196.  162.   96.  184.   81.  147.  179.  140.  112.  151.\n",
      "  109.  125.   85.  112.  177.  158.  119.  142.  100.   87.  101.  162.\n",
      "  197.  117.  142.  134.   79.  122.   74.  171.  181.  179.  164.  104.\n",
      "   91.   91.  139.  119.  146.  184.  122.  165.  124.  111.  106.  129.\n",
      "   90.   86.   92.  113.  111.  114.  193.  155.  191.  141.   95.  142.\n",
      "  123.   96.  138.  128.  102.  146.  101.  108.  122.   71.  106.  100.\n",
      "  106.  104.  114.  108.  146.  129.  133.  161.  108.  136.  155.  119.\n",
      "   96.  108.   78.  107.  128.  128.  161.  151.  146.  126.  100.  112.\n",
      "  167.  144.   77.  115.  150.  120.  161.  137.  128.  124.   80.  106.\n",
      "  155.  113.  109.  112.   99.  182.  115.  194.  129.  112.  124.  152.\n",
      "  112.  157.  122.  179.  102.  105.  118.   87.  180.  106.   95.  165.\n",
      "  117.  115.  152.  178.  130.   95.    0.  122.   95.  126.  139.  116.\n",
      "   99.    0.   92.  137.   61.   90.   90.  165.  125.  129.   88.  196.\n",
      "  189.  158.  103.  146.  147.   99.  124.  101.   81.  133.  173.  118.\n",
      "   84.  105.  122.  140.   98.   87.  156.   93.  107.  105.  109.   90.\n",
      "  125.  119.  116.  105.  144.  100.  100.  166.  131.  116.  158.  127.\n",
      "   96.  131.   82.  193.   95.  137.  136.   72.  168.  123.  115.  101.\n",
      "  197.  172.  102.  112.  143.  143.  138.  173.   97.  144.   83.  129.\n",
      "  119.   94.  102.  115.  151.  184.   94.  181.  135.   95.   99.   89.\n",
      "   80.  139.   90.  141.  140.  147.   97.  107.  189.   83.  117.  108.\n",
      "  117.  180.  100.   95.  104.  120.   82.  134.   91.  119.  100.  175.\n",
      "  135.   86.  148.  134.  120.   71.   74.   88.  115.  124.   74.   97.\n",
      "  120.  154.  144.  137.  119.  136.  114.  137.  105.  114.  126.  132.\n",
      "  158.  123.   85.   84.  145.  135.  139.  173.   99.  194.   83.   89.\n",
      "   99.  125.   80.  166.  110.   81.  195.  154.  117.   84.    0.   94.\n",
      "   96.   75.  180.  130.   84.  120.   84.  139.   91.   91.   99.  163.\n",
      "  145.  125.   76.  129.   68.  124.  114.  130.  125.   87.   97.  116.\n",
      "  117.  111.  122.  107.   86.   91.   77.  132.  105.   57.  127.  129.\n",
      "  100.  128.   90.   84.   88.  186.  187.  131.  164.  189.  116.   84.\n",
      "  114.   88.   84.  124.   97.  110.  103.   85.  125.  198.   87.   99.\n",
      "   91.   95.   99.   92.  154.  121.   78.  130.  111.   98.  143.  119.\n",
      "  108.  118.  133.  197.  151.  109.  121.  100.  124.   93.  143.  103.\n",
      "  176.   73.  111.  112.  132.   82.  123.  188.   67.   89.  173.  109.\n",
      "  108.   96.  124.  150.  183.  124.  181.   92.  152.  111.  106.  174.\n",
      "  168.  105.]\n",
      "614\n",
      "154\n",
      "768\n",
      "[ 148.   85.  183.   89.  137.  116.   78.  115.  197.  125.  110.  168.\n",
      "  139.  189.  166.  100.  118.  107.  103.  115.  126.   99.  196.  119.\n",
      "  143.  125.  147.   97.  145.  117.  109.  158.   88.   92.  122.  103.\n",
      "  138.  102.   90.  111.  180.  133.  106.  171.  159.  180.  146.   71.\n",
      "  103.  105.  103.  101.   88.  176.  150.   73.  187.  100.  146.  105.\n",
      "   84.  133.   44.  141.  114.   99.  109.  109.   95.  146.  100.  139.\n",
      "  126.  129.   79.    0.   62.   95.  131.  112.  113.   74.   83.  101.\n",
      "  137.  110.  106.  100.  136.  107.   80.  123.   81.  134.  142.  144.\n",
      "   92.   71.   93.  122.  163.  151.  125.   81.   85.  126.   96.  144.\n",
      "   83.   95.  171.  155.   89.   76.  160.  146.  124.   78.   97.   99.\n",
      "  162.  111.  107.  132.  113.   88.  120.  118.  117.  105.  173.  122.\n",
      "  170.   84.   96.  125.  100.   93.  129.  105.  128.  106.  108.  108.\n",
      "  154.  102.   57.  106.  147.   90.  136.  114.  156.  153.  188.  152.\n",
      "   99.  109.   88.  163.  151.  102.  114.  100.  131.  104.  148.  120.\n",
      "  110.  111.  102.  134.   87.   79.   75.  179.   85.  129.  143.  130.\n",
      "   87.  119.    0.   73.  141.  194.  181.  128.  109.  139.  111.  123.\n",
      "  159.  135.   85.  158.  105.  107.  109.  148.  113.  138.  108.   99.\n",
      "  103.  111.  196.  162.   96.  184.   81.  147.  179.  140.  112.  151.\n",
      "  109.  125.   85.  112.  177.  158.  119.  142.  100.   87.  101.  162.\n",
      "  197.  117.  142.  134.   79.  122.   74.  171.  181.  179.  164.  104.\n",
      "   91.   91.  139.  119.  146.  184.  122.  165.  124.  111.  106.  129.\n",
      "   90.   86.   92.  113.  111.  114.  193.  155.  191.  141.   95.  142.\n",
      "  123.   96.  138.  128.  102.  146.  101.  108.  122.   71.  106.  100.\n",
      "  106.  104.  114.  108.  146.  129.  133.  161.  108.  136.  155.  119.\n",
      "   96.  108.   78.  107.  128.  128.  161.  151.  146.  126.  100.  112.\n",
      "  167.  144.   77.  115.  150.  120.  161.  137.  128.  124.   80.  106.\n",
      "  155.  113.  109.  112.   99.  182.  115.  194.  129.  112.  124.  152.\n",
      "  112.  157.  122.  179.  102.  105.  118.   87.  180.  106.   95.  165.\n",
      "  117.  115.  152.  178.  130.   95.    0.  122.   95.  126.  139.  116.\n",
      "   99.    0.   92.  137.   61.   90.   90.  165.  125.  129.   88.  196.\n",
      "  189.  158.  103.  146.  147.   99.  124.  101.   81.  133.  173.  118.\n",
      "   84.  105.  122.  140.   98.   87.  156.   93.  107.  105.  109.   90.\n",
      "  125.  119.  116.  105.  144.  100.  100.  166.  131.  116.  158.  127.\n",
      "   96.  131.   82.  193.   95.  137.  136.   72.  168.  123.  115.  101.\n",
      "  197.  172.  102.  112.  143.  143.  138.  173.   97.  144.   83.  129.\n",
      "  119.   94.  102.  115.  151.  184.   94.  181.  135.   95.   99.   89.\n",
      "   80.  139.   90.  141.  140.  147.   97.  107.  189.   83.  117.  108.\n",
      "  117.  180.  100.   95.  104.  120.   82.  134.   91.  119.  100.  175.\n",
      "  135.   86.  148.  134.  120.   71.   74.   88.  115.  124.   74.   97.\n",
      "  120.  154.  144.  137.  119.  136.  114.  137.  105.  114.  126.  132.\n",
      "  158.  123.   85.   84.  145.  135.  139.  173.   99.  194.   83.   89.\n",
      "   99.  125.   80.  166.  110.   81.  195.  154.  117.   84.    0.   94.\n",
      "   96.   75.  180.  130.   84.  120.   84.  139.   91.   91.   99.  163.\n",
      "  145.  125.   76.  129.   68.  124.  114.  130.  125.   87.   97.  116.\n",
      "  117.  111.  122.  107.   86.   91.   77.  132.  105.   57.  127.  129.\n",
      "  100.  128.   90.   84.   88.  186.  187.  131.  164.  189.  116.   84.\n",
      "  114.   88.   84.  124.   97.  110.  103.   85.  125.  198.   87.   99.\n",
      "   91.   95.   99.   92.  154.  121.   78.  130.  111.   98.  143.  119.\n",
      "  108.  118.  133.  197.  151.  109.  121.  100.  124.   93.  143.  103.\n",
      "  176.   73.  111.  112.  132.   82.  123.  188.   67.   89.  173.  109.\n",
      "  108.   96.  124.  150.  183.  124.  181.   92.  152.  111.  106.  174.\n",
      "  168.  105.]\n",
      "(614,) (154,)\n"
     ]
    }
   ],
   "source": [
    "#here we read the data where X is the input and Y is the output\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "length = len(dataset.values)\n",
    "width = dataset.ndim-1\n",
    "ratio = int(length*0.8) #training ratio (includes validation) vs test ratio \n",
    "\n",
    "x_train = dataset.values[0:ratio,0:width]\n",
    "y_train = dataset.values[0:ratio:,width]\n",
    "\n",
    "x_test = dataset.values[ratio:,0:width]\n",
    "y_test = dataset.values[ratio:,width]\n",
    "\n",
    "print (y_train)\n",
    "\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)\n",
    "\n",
    "#checking lengths\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(x_train)+len(x_test))\n",
    "\n",
    "print (y_train)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "#scatterplots\n",
    "#plt.scatter(creditcard.Class, creditcard.V2, color='red')\n",
    "#plt.scatter(creditcard.Class, creditcard.V5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 293\n",
      "Trainable params: 293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#here we create the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "model = Sequential()\n",
    "#layers\n",
    "model.add(Dense(12, input_dim=14, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.1) # lr is the learning rate\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_65_input to have shape (14,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a2fb76723eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#here we train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1638\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1483\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_65_input to have shape (14,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "#here we train the model\n",
    "model.fit(x_train, y_train, epochs=15, batch_size=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 511 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "511/511 [==============================] - 0s 271us/step - loss: -1911.3079 - acc: 0.0000e+00 - val_loss: -1869.4382 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "511/511 [==============================] - 0s 97us/step - loss: -1911.3079 - acc: 0.0000e+00 - val_loss: -1869.4382 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "511/511 [==============================] - 0s 88us/step - loss: -1911.3079 - acc: 0.0000e+00 - val_loss: -1869.4382 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "511/511 [==============================] - 0s 74us/step - loss: -1911.3079 - acc: 0.0000e+00 - val_loss: -1869.4382 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "511/511 [==============================] - 0s 78us/step - loss: -1911.3079 - acc: 0.0000e+00 - val_loss: -1869.4382 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x49920ebe10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we validate the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.7103 - acc: 0.6480\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - 0s 226us/step - loss: 0.6787 - acc: 0.6300\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - 0s 238us/step - loss: 0.6449 - acc: 0.6620\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - 0s 248us/step - loss: 0.6422 - acc: 0.6400\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - 0s 195us/step - loss: 0.6334 - acc: 0.6480\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - 0s 203us/step - loss: 0.6332 - acc: 0.6460\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - 0s 262us/step - loss: 0.6460 - acc: 0.6340\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - 0s 233us/step - loss: 0.6506 - acc: 0.6620\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - 0s 278us/step - loss: 0.6369 - acc: 0.6360\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - 0s 344us/step - loss: 0.6278 - acc: 0.6460\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - 0s 342us/step - loss: 0.6282 - acc: 0.6540\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - 0s 322us/step - loss: 0.6368 - acc: 0.6120\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - 0s 310us/step - loss: 0.6262 - acc: 0.6440\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - 0s 250us/step - loss: 0.6382 - acc: 0.6280\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - 0s 232us/step - loss: 0.6294 - acc: 0.6540\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - 0s 234us/step - loss: 0.6710 - acc: 0.6440\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - 0s 264us/step - loss: 0.6767 - acc: 0.6360\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - 0s 258us/step - loss: 0.6641 - acc: 0.6360\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - 0s 324us/step - loss: 0.6599 - acc: 0.6360\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - 0s 292us/step - loss: 0.6574 - acc: 0.6360\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - 0s 284us/step - loss: 0.6566 - acc: 0.6360\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - 0s 324us/step - loss: 0.6561 - acc: 0.6360\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - 0s 238us/step - loss: 0.6560 - acc: 0.6360\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - 0s 228us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 25/150\n",
      "500/500 [==============================] - 0s 268us/step - loss: 0.6560 - acc: 0.6360\n",
      "Epoch 26/150\n",
      "500/500 [==============================] - 0s 300us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 27/150\n",
      "500/500 [==============================] - 0s 278us/step - loss: 0.6562 - acc: 0.6360\n",
      "Epoch 28/150\n",
      "500/500 [==============================] - 0s 276us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 29/150\n",
      "500/500 [==============================] - 0s 294us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 30/150\n",
      "500/500 [==============================] - 0s 260us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 31/150\n",
      "500/500 [==============================] - 0s 250us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 32/150\n",
      "500/500 [==============================] - 0s 254us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 33/150\n",
      "500/500 [==============================] - 0s 290us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 34/150\n",
      "500/500 [==============================] - 0s 300us/step - loss: 0.6565 - acc: 0.6360\n",
      "Epoch 35/150\n",
      "500/500 [==============================] - 0s 292us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 36/150\n",
      "500/500 [==============================] - 0s 304us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 37/150\n",
      "500/500 [==============================] - 0s 292us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 38/150\n",
      "500/500 [==============================] - 0s 268us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 39/150\n",
      "500/500 [==============================] - 0s 238us/step - loss: 0.6561 - acc: 0.6360\n",
      "Epoch 40/150\n",
      "500/500 [==============================] - 0s 236us/step - loss: 0.6561 - acc: 0.6360\n",
      "Epoch 41/150\n",
      "500/500 [==============================] - 0s 236us/step - loss: 0.6560 - acc: 0.6360\n",
      "Epoch 42/150\n",
      "500/500 [==============================] - 0s 290us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 43/150\n",
      "500/500 [==============================] - 0s 280us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 44/150\n",
      "500/500 [==============================] - 0s 276us/step - loss: 0.6561 - acc: 0.6360\n",
      "Epoch 45/150\n",
      "500/500 [==============================] - 0s 248us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 46/150\n",
      "500/500 [==============================] - 0s 252us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 47/150\n",
      "500/500 [==============================] - 0s 266us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 48/150\n",
      "500/500 [==============================] - 0s 262us/step - loss: 0.6561 - acc: 0.6360\n",
      "Epoch 49/150\n",
      "500/500 [==============================] - 0s 262us/step - loss: 0.6558 - acc: 0.6360\n",
      "Epoch 50/150\n",
      "500/500 [==============================] - 0s 262us/step - loss: 0.6559 - acc: 0.6360\n",
      "Epoch 51/150\n",
      "500/500 [==============================] - 0s 256us/step - loss: 0.6567 - acc: 0.6360\n",
      "Epoch 52/150\n",
      " 10/500 [..............................] - ETA: 0s - loss: 0.7332 - acc: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-a76d927bbd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "dataset = pd.read_csv('./diabetes.csv', delimiter=\",\")\n",
    "Xtrain = dataset.values[:500,0:8]\n",
    "Ytrain = dataset.values[:500,8]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=8, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(16, activation='selu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xtrain, Ytrain, epochs=150, batch_size=10)\n",
    "model.fit(Xtrain, Ytrain, epochs=5, batch_size=32, validation_split=1/6)\n",
    "\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
